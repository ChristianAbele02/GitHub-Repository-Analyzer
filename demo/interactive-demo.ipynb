{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Repository Analyzer - Interactive Demo\n",
    "\n",
    "This notebook demonstrates how to use the GitHub Repository Analyzer interactively in Jupyter.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before running this notebook:\n",
    "1. Install dependencies: `pip install -r requirements.txt`\n",
    "2. Set up your GitHub token in a `.env` file\n",
    "3. Install Jupyter: `pip install jupyter ipywidgets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import the analyzer\n",
    "from main import GitHubRepositoryAnalyzer\n",
    "\n",
    "# Set up plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and initialize analyzer\n",
    "load_dotenv()\n",
    "github_token = os.getenv('GITHUB_TOKEN')\n",
    "\n",
    "if not github_token:\n",
    "    print(\"❌ Please set your GITHUB_TOKEN in a .env file\")\n",
    "else:\n",
    "    print(\"✅ GitHub token loaded successfully\")\n",
    "    analyzer = GitHubRepositoryAnalyzer(token=github_token)\n",
    "    print(\"✅ Analyzer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Repository Search and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for Python machine learning repositories\n",
    "print(\"🔍 Searching for Python ML repositories...\")\n",
    "\n",
    "repositories = analyzer.search_repositories(\n",
    "    query=\"language:python topic:machine-learning\",\n",
    "    max_repos=150,\n",
    "    time_window=\"last 6 months\"\n",
    ")\n",
    "\n",
    "print(f\"📊 Found {len(repositories)} repositories\")\n",
    "\n",
    "# Display top repositories\n",
    "if repositories:\n",
    "    top_repos = sorted(repositories, key=lambda x: x['stars'], reverse=True)[:10]\n",
    "    \n",
    "    df_top = pd.DataFrame([\n",
    "        {\n",
    "            'Repository': repo['full_name'],\n",
    "            'Stars': repo['stars'],\n",
    "            'Forks': repo['forks'],\n",
    "            'Language': repo.get('language', 'Unknown')\n",
    "        }\n",
    "        for repo in top_repos\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n🏆 Top 10 Repositories:\")\n",
    "    display(df_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive analysis\n",
    "print(\"🔬 Performing analysis...\")\n",
    "\n",
    "analysis_results = analyzer.analyze_all(\n",
    "    perform_clustering=True,\n",
    "    predict_trends=True\n",
    ")\n",
    "\n",
    "print(\"✅ Analysis completed!\")\n",
    "\n",
    "# Display summary statistics\n",
    "summary = analysis_results.get('summary', {})\n",
    "print(f\"\\n📈 Summary Statistics:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"  • {key.replace('_', ' ').title()}: {value:,}\" if isinstance(value, (int, float)) else f\"  • {key.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Language Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze programming languages\n",
    "languages = analysis_results.get('languages', [])\n",
    "\n",
    "if languages:\n",
    "    df_languages = pd.DataFrame(languages)\n",
    "    \n",
    "    # Display top languages\n",
    "    print(\"💻 Programming Languages Analysis:\")\n",
    "    display(df_languages.head(10)[['language', 'count_stars', 'sum_stars', 'mean_stars', 'popularity_score']])\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Repository count by language\n",
    "    top_10_langs = df_languages.head(10)\n",
    "    ax1.bar(range(len(top_10_langs)), top_10_langs['count_stars'])\n",
    "    ax1.set_xlabel('Programming Languages')\n",
    "    ax1.set_ylabel('Repository Count')\n",
    "    ax1.set_title('Repository Count by Language')\n",
    "    ax1.set_xticks(range(len(top_10_langs)))\n",
    "    ax1.set_xticklabels(top_10_langs['language'], rotation=45)\n",
    "    \n",
    "    # Average stars by language\n",
    "    ax2.bar(range(len(top_10_langs)), top_10_langs['mean_stars'])\n",
    "    ax2.set_xlabel('Programming Languages')\n",
    "    ax2.set_ylabel('Average Stars per Repository')\n",
    "    ax2.set_title('Average Quality by Language')\n",
    "    ax2.set_xticks(range(len(top_10_langs)))\n",
    "    ax2.set_xticklabels(top_10_langs['language'], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze repository topics\n",
    "topics = analysis_results.get('topics', [])\n",
    "\n",
    "if topics:\n",
    "    df_topics = pd.DataFrame(topics)\n",
    "    \n",
    "    print(\"🏷️ Repository Topics Analysis:\")\n",
    "    display(df_topics.head(15))\n",
    "    \n",
    "    # Create topic visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    top_20_topics = df_topics.head(20)\n",
    "    plt.barh(range(len(top_20_topics)), top_20_topics['count'])\n",
    "    plt.xlabel('Number of Repositories')\n",
    "    plt.ylabel('Topics')\n",
    "    plt.title('Top 20 Repository Topics')\n",
    "    plt.yticks(range(len(top_20_topics)), top_20_topics['topic'])\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, (count, percentage) in enumerate(zip(top_20_topics['count'], top_20_topics['percentage'])):\n",
    "        plt.text(count + 0.5, i, f'{percentage:.1f}%', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Trend Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trend predictions\n",
    "predictions = analysis_results.get('predictions', {})\n",
    "\n",
    "if predictions:\n",
    "    print(\"📈 Trend Predictions:\")\n",
    "    \n",
    "    # Create DataFrame for predictions\n",
    "    pred_data = []\n",
    "    for language, pred in predictions.items():\n",
    "        pred_data.append({\n",
    "            'Language': language,\n",
    "            'Current Score': pred['current_score'],\n",
    "            'Growth Rate (%)': pred['growth_rate'],\n",
    "            'Trend Direction': pred['trend_direction'],\n",
    "            'Confidence (%)': pred['confidence']\n",
    "        })\n",
    "    \n",
    "    df_predictions = pd.DataFrame(pred_data)\n",
    "    df_predictions = df_predictions.sort_values('Growth Rate (%)', ascending=False)\n",
    "    \n",
    "    display(df_predictions)\n",
    "    \n",
    "    # Visualize growth predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    colors = ['green' if x > 0 else 'red' for x in df_predictions['Growth Rate (%)']]\n",
    "    \n",
    "    plt.barh(range(len(df_predictions)), df_predictions['Growth Rate (%)'], color=colors, alpha=0.7)\n",
    "    plt.xlabel('Predicted Growth Rate (%)')\n",
    "    plt.ylabel('Programming Languages')\n",
    "    plt.title('Language Growth Predictions')\n",
    "    plt.yticks(range(len(df_predictions)), df_predictions['Language'])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Interactive Time Window Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widget for time window selection\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Time window options\n",
    "time_windows = [\n",
    "    \"last 12 months\",\n",
    "    \"last 6 months\", \n",
    "    \"last month\",\n",
    "    \"this month\",\n",
    "    \"last two weeks\",\n",
    "    \"last week\",\n",
    "    \"today\"\n",
    "]\n",
    "\n",
    "# Create widgets\n",
    "query_widget = widgets.Text(\n",
    "    value=\"language:javascript topic:react\",\n",
    "    description=\"Query:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "time_widget = widgets.Dropdown(\n",
    "    options=time_windows,\n",
    "    value=\"last 6 months\",\n",
    "    description=\"Time Window:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "max_repos_widget = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=50,\n",
    "    max=500,\n",
    "    step=50,\n",
    "    description=\"Max Repos:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description=\"Analyze\",\n",
    "    button_style='primary'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def analyze_button_click(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"🔍 Analyzing: {query_widget.value}\")\n",
    "        print(f\"⏰ Time window: {time_widget.value}\")\n",
    "        print(f\"📊 Max repositories: {max_repos_widget.value}\")\n",
    "        \n",
    "        try:\n",
    "            # Clear previous data\n",
    "            analyzer.repositories_data = []\n",
    "            \n",
    "            # Search repositories\n",
    "            repos = analyzer.search_repositories(\n",
    "                query=query_widget.value,\n",
    "                max_repos=max_repos_widget.value,\n",
    "                time_window=time_widget.value\n",
    "            )\n",
    "            \n",
    "            if repos:\n",
    "                print(f\"✅ Found {len(repos)} repositories\")\n",
    "                \n",
    "                # Quick analysis\n",
    "                analysis = analyzer.analyze_all(\n",
    "                    perform_clustering=False,\n",
    "                    predict_trends=False\n",
    "                )\n",
    "                \n",
    "                summary = analysis.get('summary', {})\n",
    "                print(f\"\\n📈 Quick Stats:\")\n",
    "                print(f\"  • Total Stars: {summary.get('total_stars', 0):,}\")\n",
    "                print(f\"  • Average Stars: {summary.get('total_stars', 0) / len(repos):.1f}\")\n",
    "                print(f\"  • Unique Languages: {summary.get('unique_languages', 0)}\")\n",
    "                \n",
    "                # Show top repositories\n",
    "                top_5 = sorted(repos, key=lambda x: x['stars'], reverse=True)[:5]\n",
    "                print(f\"\\n🏆 Top 5 Repositories:\")\n",
    "                for i, repo in enumerate(top_5, 1):\n",
    "                    print(f\"  {i}. {repo['full_name']} - ⭐ {repo['stars']:,}\")\n",
    "            else:\n",
    "                print(\"❌ No repositories found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "button.on_click(analyze_button_click)\n",
    "\n",
    "# Display widgets\n",
    "print(\"🎛️ Interactive Repository Analysis\")\n",
    "display(query_widget, time_widget, max_repos_widget, button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive insights report\n",
    "insights = analyzer.generate_insights_report()\n",
    "\n",
    "print(\"📝 Insights Report Generated:\")\n",
    "print(\"\\n🎯 Top Findings:\")\n",
    "for i, finding in enumerate(insights.get('top_findings', []), 1):\n",
    "    print(f\"  {i}. {finding}\")\n",
    "\n",
    "print(\"\\n💡 Recommendations:\")\n",
    "for i, rec in enumerate(insights.get('recommendations', []), 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "# Save all data\n",
    "print(\"\\n💾 Saving analysis data...\")\n",
    "saved_files = analyzer.save_all_data(filename_prefix=\"notebook_analysis\")\n",
    "\n",
    "print(\"✅ Files saved:\")\n",
    "for file_type, filename in saved_files.items():\n",
    "    print(f\"  • {file_type}: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Try different search queries and time windows\n",
    "- Explore the saved CSV and JSON files\n",
    "- Check out the Python script examples in the `examples/` directory\n",
    "- Modify the analysis parameters for your specific research needs\n",
    "\n",
    "Happy analyzing! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}